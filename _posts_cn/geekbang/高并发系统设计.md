---
title: 高并发系统设计 40 问
tags:
  - 极客时间笔记
date: 2019-09-25
---

> 本文总结自极客时间专栏，[高并发系统设计40问](https://time.geekbang.org/column/intro/230)，持续更新

## 支持原版

![海报](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/海报.jpg)

## 为什么要学习高并发系统设计

**思考题**

- 微博中，明星动辄拥有几千万甚至上亿的粉丝，如何保证明星发布的内容让粉丝实时地看到
- 淘宝双十一，如何保证衣服不会超卖
- 12306 订购火车票，如何保证千万人访问的同时也能支持正常抢票

同样是缓存的使用，在低并发下你只需要了解基本的使用方式，但在高并发场景下需要关注**缓存命中率、如何应对缓存穿透、如何避免雪崩、如何解决缓存一致性等问题**，增加了设计方案的复杂度，对设计者能力的要求也会更高。

## 学习目标

- 掌握高并发系统设计的“套路”
- 理解基本的系统设计思想，对新的知识触类旁通，举一反三
- 突破技术的瓶颈，突破所处平台的限制，具备一个优秀架构师的资质

虽说每家公司所处的行业不同，业务场景不同，但是设计和优化的思想却是万变不离其宗。

本篇总结里的经验是一个个的“小套路”，它们相互联系，形成一套指引进行高并发系统设计的指示体系，其中包括了理论知识的讲解、问题场景的介绍、问题分析的过程，以及解决问题的思路。

当掌握这些“套路”后，就能明确地知道，系统处于某一阶段时，可能会面临的问题，然后及时找到架构设计优化的思路解决这些问题，提升系统性能。

## 系统的演进过程

- 最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系
- 随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件来解决问题，社区没有合适解决方案的前提下才自己造轮子
- 对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有问题

**高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的**

## 高并发系统的通用设计方法是什么

目标是抵抗巨大流量的冲击，让流量更加平稳地被系统中的服务和组件处理。

> 课程比喻： 从古至今，长江和黄河流域水患不断。
> **远古时期，大禹曾拓宽河道，清除淤沙让流水更加流畅**
> **都江堰作为史上最成功的治水案例之一，用引流将岷江之水分流到多个支流中，以分担水流压力**
> **三门峡和葛洲坝通过建造水库将水引入水库先存储起来，然后再想办法把水库中的水缓缓地排出去，以此提高下游的抗洪能力**

在应对高并发大流量时也会采用类似“抵御洪水”的方案：
- Scale-out（横向扩展）：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分开，让每个服务器都承担一部分并发和流量
- 缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击
- 异步：在某些场景下，未处理完成之前，可以先让请求返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求

### Scale-up 和 Scale-out

- Scale-up，通过购买性能更好的硬件来提升系统的并发处理能力，比如目前 4 核 4G 每秒可以处理 200 次请求，如果要处理 400 次请求呢？把机器的硬件提升到 8 核 8G（硬件资源的提升可能不是线性，仅供参考）
- Scale-out，通过将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击

**使用时机**

一般在系统设计初期会考虑使用 Scale-up 的方式，方案简单，但系统并发超过了单机极限时，就需要使用 Scale-out 的方式了。

Scale-out 虽可以突破单机限制，但也会引入一些复杂问题 —— 如何保证高可用？如何进行状态同步？如何无感知增加和删除节点？

### 缓存

使用缓存的主要作用是提升系统的访问性能。

可以将任何降低响应事件的中间存储都称为缓存，缓存的思想遍布很多设计领域，比如操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。

### 异步处理

同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方响应时间较长，会造成调用方长久的阻塞，在高并发系统下会造成整体系统性能下降甚至发生雪崩。

异步调用不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。

异步调用在大规模高并发系统中被大量使用，比如 12306。

订票时，页面会显示系统正在排队，代表着系统在异步处理订票请求。系统中查询余票、下单和更改余票状态都是比较耗时的操作，可能涉及多个内部系统的互相调用，如果是同步调用就会像 12306 刚刚上线时那样，高峰期永远不可能下单成功。

**处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了，自然就能接收更多的用户订票请求，系统承受高并发的能力也就提升了。**

![12306异步处理订票操作示意图](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/12306异步处理订票操作示意图.png)

## 架构分层

> 在系统从 0 到 1 的阶段，为了让系统快速上线，通常是不考虑分层的。但是随着业务越来越复杂，大量的代码纠缠在一起，会出现逻辑不清晰、各模块相互依赖、代码扩展性差、改动一处就牵一发而动全身等问题

### 什么是分层架构

它将整个系统拆分成 N 个层次，每个层次有独立的职责，多个层次协同提供完整的功能。

![mvc架构图](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/mvc架构图.png)

MVC 架构将整体的系统分成了 Model（模型）、View（视图）和 Controller（控制器）三个层次，也就是将用户视图和业务处理隔离开，并且通过控制器连接起来，很好的实现了表现和逻辑的解耦，是一种标准的软件分层结构。

**另外一种分层方式是将整体架构分为表现层、逻辑层和数据访问层：**

- 表现层，顾名思义，就是展示数据结果和接受用户指令的，最靠近用户的一层
- 逻辑层负责复杂业务的具体实现
- 数据访问层处理和存储之间的交互

### 例子

**OSI 网络模型**

![网络分层模型](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/网络分层模型.png)

它把整个网络分成了七层，自下而上分别是**物理层、数据链路层、网络层、传输层、会话层、表示层和应用层**

TCP/IP 协议把网络简化成了四层，即**链路层、网络层、传输层和应用层**。

**每一层各司其职又互相帮助**。

网络层负责端到端的寻址和建立连接，传输层负责端到端的数据传输等，相邻两层有数据交互。这样做**隔离了关注点，让不同的层专注做不同的事情。**

**Linux 文件系统**

![文件系统分层](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/文件系统分层.png)

文件系统最上层是虚拟文件系统(VFS)，用来屏蔽不同的文件系统之间的差异，提供统一的系统调用接口。虚拟文件系统的下层是 Ext3、Ext4 等各种文件系统，再向下是为了屏蔽不同硬件设备的实现细节，抽象出单独的一层 ———— 通用块设备层，再往下就是不同类型的磁盘了。

### 分层的好处

1. **简化系统设计，不同的层专注做事**
2. **高复用**
3. **更容易做横向扩展**

业务逻辑里面包含比较复杂的计算，导致 CPU 成为性能瓶颈，这样可以将逻辑层单独抽取出来独立部署，只对逻辑层做扩展，相对于针对整体系统扩展付出的代价小。

**架构分层和高并发设计的关系是怎样的？**横向扩展是高并发系统设计的常用方法之一，既然分层的架构可以为横向扩展提供便捷，那么支撑高并发的系统一定是分层的系统。

### 怎么分层

分层设计最主要的一点就是需要**理清每个层次的边界是什么**。

**例子**

任何一个系统中都有用户系统，最基本的接口是返回用户信息的接口，它调用逻辑层的 GetUser 方法，GetUser 方法又和 User DB 交互获取数据。

此时，产品提出一个需求，在 APP 中展示用户信息的时候，如果用户不存在，那么要自动给用户创建一个用户。同时，要做一个 HTML5 的页面，HTML5 页面要保留之前的逻辑，也就是不需要创建用户。这时逻辑层的边界就变得不清晰，表现层也承担了一部分的业务逻辑（将获取用户和创建用户接口编排起来）。

![获取用户信息接口的进化](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/获取用户信息接口的进化.png)

**进化！**

![阿里系统分层的规约](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/阿里系统分层的规约.png)

- 终端显示层：各端模板渲染并执行显示的层
- 开放接口层：将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等
- Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等
- Service 层：业务逻辑层
- Manager 层：通用业务处理层。这一层主要有两个作用，其一，可以将原先 Service 层的一些通用能力下沉到这一层，比如与缓存和存储交互策略，中间件的介入；其二，可以在这一层封装对第三方接口的调用，比如调用支付系统，调用审核服务等
- DAO 层：数据访问层，与底层 MySQL、Oracle、Hbase 等进行数据交互
- 外部接口或第三方平台：包括其他部门 RPC 开发接口，基础平台，其他公司的 HTTP 接口

Manager 层提供原子的服务接口，Service 层负责依据业务逻辑来编排原子接口。

Manager 层提供创建用户和获取用户信息的接口，而 Service 层负责将这两个接口组装起来。这样就把原先散步在表现层的业务逻辑都统一到了 Service 层，每一层的边界就非常清晰了。

除此之外，**分层架构需要考虑的另一个因素**是层次之间一定是相邻层互相依赖，**数据的流转也只能在相邻的两层之间流转**。

### 分层系统的不足

**分层架构最主要的一个缺陷就是增加了代码的复杂度。**

同时，因为每个层次独立部署，层次间通过网络来交互，那么多层的架构在性能上会有损耗。

> 这也是为什么服务化架构性能要比单体架构略差的原因，也就是所谓的“多级一跳”问题

### 总结

分层架构是软件设计思想的外在体现，是一种实现方式。一些熟知的软件设计原则都在分层架构中有所体现。

**单一职责原则**规定每个类只有单一的功能，在这里可以引申为每一层拥有单一职责，且层与层之间边界清晰；

**迪米特法则**原意是一个对象应当对其他对象有尽可能少的了解，在分层架构的体现是数据的交互不能跨层，只能在相邻层之间进行；

**开闭原则**要求软件对扩展开放，对修改关闭。它的含义其实就是将抽象层和实现层分离，抽象层是对实现层共有特征的归纳总结，不可以修改，但是具体的实现可以是无限扩展，随意替换的。

## 如何提高系统性能

### 高并发系统设计的三大目标

**高性能、高可用、可扩展**

高并发**指运用设计手段让系统能够处理更多的用户并发请求，承受更大的流量。**是一切架构设计的背景和前提，在每秒一次请求和每秒一万次请求这两种不同的场景下，分别做到毫秒级响应时间和五个九（99.999%）的可用性，无论是设计难度还是方案的复杂度，都不在一个级别。

性能和可用性**是实现高并发系统设计必须考虑的因素。**

性能反应了系统的使用体验，可用性则表示系统可以正常服务用户的时间。

流量分为平时流量和峰值流量两种，峰值流量可能会是平时流量的几倍甚至几十倍，在应对峰值流量的时候，通常需要在架构和方案上做更多的准备。

易于扩展的系统能在短时间内迅速完成扩容，更加平稳地承担峰值流量。

这也是**可扩展性**被认作高并发系统设计需要考虑的因素之一的原因。

### 如何提升系统性能？

#### 性能优化原则

- **性能优化一定不能盲目，一定是问题导向的**
- **性能优化也遵循“八二原则”**，用 20% 的精力解决 80% 的性能问题，在优化过程中一定要抓住主要矛盾，优先优化主要的性能瓶颈点
- **性能优化也要有数据支撑**，在优化过程中，要时刻了解你的优化让响应时间减少了多少，提升了多少吞吐量
- **性能优化的过程是持续的**，需要持续不断地寻找性能瓶颈，制定优化方案，直到达到目标为止。

#### 性能的度量指标

度量性能的指标是系统接口的响应时间，要知道一段时间的性能是什么样的，需要收集这段时间的响应时间数据，依据一些统计方法计算出特征值，这些特征值就能够代表这段时间的性能情况。常见特征值有以下几类：

- 平均值

平均值 = 响应时间总和 / 总请求数

平均值可以在一定程度上反应这段时间的性能，但敏感度比较差。**如果这段时间有少量慢请求，在平均值上并不能如实的反应。**

- 最大值

这段时间内所有请求中响应时间最长的值，问题在于过于敏感。

- 分位值

![分位值示意图](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/分位值示意图.png)

分位值有很多种，比如 90 分位、95 分位、75 分位。

以 90 分位为例，把这段时间请求的响应时间从小到大排序，加入一共有 100 个请求，那么排在第 90 位的响应时间就是 90 分位值。

**分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感。**

分位值是最适合作为单位时间段内响应时间统计值来使用的，在实际工作中也应用最多，平均值也可以作为一个参考值来使用。

但脱离了并发来谈性能是没有意义的，通常使用**吞吐量**或者**同时在线用户数**来度量并发和流量，使用吞吐量的情况会更多一些。注意，**这两个指标是呈倒数关系的。**

响应时间 1s 时，吞吐量是每秒 1 次，响应时间缩短到 10ms，那么吞吐量就上升到每秒 100 次。所以，一般度量性能时都会同时兼顾吞吐量和响应时间，比如设计性能优化目标时，通常会这样描述：**在每秒 1 万次请求量下，响应时间 99 分位值在 10ms 以下。**

从用户使用体验的角度来看，200ms 是第一个分界点：接口的响应时间在 200ms 之内，用户是感觉不到延迟的，就像是瞬时发生的一样。而 1s 是另外一个分界点：接口的响应时间在 1s 之内时，用户虽然可以感受到一些延迟，但却是可以接受的，超过 1s 之后用户就会有明显等待的感觉，等待时间越长，用户的使用体验就越差。所以，**健康系统的 99 分位值的响应事件通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。**

#### 高并发下的性能优化

假设你有一个系统，这个系统中处理核心只有一个，执行的任务的响应事件都在 10ms，吞吐量是在每秒 100 次。

主要有**两种思路**来针对这个系统做性能优化：一种是提高系统的处理核心数，另一种是减少单次任务的响应时间。

- **提高系统的处理核心数**

计算机领域的阿姆达尔定律(Amdahl's law)是吉恩-阿姆达尔在 1967 年提出的。描述了并发进程数与响应时间之间的关系，含义是在固定负载下，并行计算的加速比，也就是并行化之后效率提升情况，可以用下面公式来表示：

> (Ws + Wp)/(Ws + Wp/s)

其中，Ws 表示任务中的串行计算量，Wp 表示任务中的并行计算量，s 表示并行进程数。从这个公式中可以推导出另一个公式：

> 1/(1 - p + p / s)

其中，s 表示并行进程数，p 表示任务中并行部分的占比。当 p 为 1 时，也就是完全并行时，加速比与并行进程数相等；等 p 为 0 时，即完全串行时，加速比为 1，也就是说完全无加速；当 s 趋近于无穷大的时候，加速比就等于 1/(1-p)，和 p 成正比。**特别是，当 p 为 1 时，加速比趋近于无穷大。**

看上去无限制增加处理核心数就能无限制地提升性能，从而提升系统处理高并发的能力。但其实随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的**拐点模型**。

![性能测试的拐点模型](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/性能测试的拐点模型.png)

如上图，在评估系统性能时通常需要做压力测试，目的就是找到系统的“拐点”，从而知道系统的承载能力，便于找到系统的瓶颈，持续优化系统性能。

- **减少单次任务的响应时间**

**要减少任务响应时间，首先需要确定系统是 CPU 密集型还是 IO 密集型，不同类型的系统性能优化方式不尽相同。**

CPU 密集型系统中，需要处理大量的 CPU 运算，选用更高效的算法或者减少运算次数就是这类系统重要的优化手段。

IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里的 IO 指的是磁盘 IO 和网络 IO。熟知的系统大部分都属于 IO 密集型，比如数据库系统、缓存系统、Web 系统。这类系统的性能瓶颈可能出现在系统内部，也可能是依赖其他系统，发现这类系统性能瓶颈的手段主要有两类。

- 采用工具
- 监控

找到系统的瓶颈点之后，再根据实际的问题来进行优化，制定不同的性能优化方案来应对不同的性能问题。

### 总结

- 数据优先，新系统上线之前一定要把性能监控系统做好
- 掌握一些性能优化工具和方法
- 计算机基础知识很重要，比如网络、操作系统等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，才能在性能优化过程中游刃有余

## 怎样做到高可用

**高可用性(High Availability, HA)**指系统具备较高的无故障运行的能力。

### 可用性的度量

- **MTBF(Mean Time Between Failure，平均故障间隔)**，代表两次故障的间隔时间，系统正常运转的平均时间，时间越长，系统稳定性越高。
- **MTTR(Mean Time To Repair，故障平均恢复时间)**，也可以理解成平均故障时间，值越小，故障对用户的影响越小。

**公式**

> Availability = MTBF / (MTBF + MTTR)

结果是一个比例，代表系统的可用性。

![不同可用性标准下允许的故障时间](https://sherlockblaze.com/resources/img/time-geekbang/高并发系统设计/不同可用性标准下允许的故障时间.png)

一般来说，核心业务系统的可用性需要达到四个九，非核心系统的可用性最多容忍到三个九。

### 高可用系统设计思路

**一个成熟系统的可用性需要从系统设计和系统运维两方面来做保障，两者共同作用，缺一不可。**

**系统设计**

“Design for failure” 是高可用系统设计时秉承的第一原则。在承担百万 QPS 的高并发系统中，集群中机器的数量成百上千台，单机的故障是常态，几乎每一天都有发生故障的可能。

做系统设计时，要把发生故障作为一个重要的考虑点，预先考虑如何自动化地发现故障，发生故障之后要如何解决。

同时，需要掌握一些具体的优化方法，比如**failover(故障转移)、超时控制以及降级和限流。**

一般来说，发生 faileover 的节点可能有两种情况：

1. 在完全对等的节点之间做 failover
2. 在不对等的节点之间，即系统中存在主节点也存在备节点

在对等节点之间做 failover 相对简单，这类系统中所有节点都承担读写流量，并且节点中不保存状态，每个节点都可以作为另一个节点的镜像。这种情况下，如果访问某一个节点失败，简单地随机访问另一个节点就好了。

针对不对等节点的 failover 机制会复杂很多。比如有一个主节点，多台备用节点，这些备用节点可以是热备，也可以是冷备，那么就需要在代码中控制如何检测主备机器是否故障，以及如何做主备切换。

使用最广泛的故障检测机制是“心跳”。可以在客户端上定期地向主节点发送心跳包，也可以从备份节点上定期发送心跳包。当一段时间内未收到心跳包，就可以认为主节点已经发生故障，可以触发选主的操作。

选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比如：Paxos、Raft。

除了故障转移之外，对于系统间调用超时的控制也是高可用系统设计的一个重要考虑方面。

复杂的高并发系统通常会有很多的系统模块组成，同时也会依赖很多的组件和服务，比如说缓存组件，队列服务等等。它们之间的调用最怕的就是延迟而非失败，因为失败通常是瞬时的，可以通过重试的方式解决。而一旦调用某一个模块或服务发生较大的延迟，调用方就会阻塞在这次调用上，它已经占用的资源得不到释放。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉。

**如何确定超时时间？**

超时时间短了，会造成大量的超时错误，对用户体验产生影响；超时时间长了，又起不到作用。

可以通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间。

